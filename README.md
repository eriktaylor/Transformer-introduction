# Transformer
This is an overview of the transformer architecture with emphasis on vision-language applications. I'll include short articles to introduce the topics and mini-projects that span my recent work in vision, vision-language, and generative AI. 

**This site is under active development.**

## Introduction
The Transformer is a general purpose architecture used for machine learning. It is the backend for generative AI and foundation models that power recent applications. I'll focus on the technology that helped to build models used in ChatGPT, Google Gemini, Stable Diffusion, and others. This is an overview about how the transformer architecture is used for vision applications starting from the basics to current state-of-the-art multi-modal models.

## Short articles on transformers

Each topic below is broken down into short articles that require about 10 minutes to read.

[Transformer introduced for NLP (2017)](https://medium.com/@erikntaylor/transformer-introduced-for-nlp-80c02858064d)

Vision transformer (2020)

Vision-language transformer

Multimodal and foundation models

## Mini-projects using generative AI

[Response to 3 papers from 2024 relating to the AI scientist](https://medium.com/@erikntaylor/review-of-ai-scientist-and-related-2024-papers-by-a-human-scientist-with-help-from-gpt-4o-b53c101943ac)

Topics: AI paper summary, idea generation, paper review, the AI Scientist.

[Visualizing the AI Scientist](https://medium.com/@erikntaylor/visualizing-the-ai-scientist-2aa820ffe1f6)

Topics: generative AI, text-to-image, image-to-text.

[mini-project: text to video]

[mini-project: LORA for diffusion models]

If this list grows substantially, I'll move this into a new repository on generative AI.
