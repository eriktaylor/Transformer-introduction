# Transformer
This is an overview of the transformer architecture with emphasis on vision-language applications. I'll include short articles to introduce the topics and mini-projects that span my recent work in vision, vision-language, and generative AI. 

**This site is under active development.**

## Introduction
The Transformer is a general purpose architecture used for machine learning. It is the backend for generative AI and foundation models that power recent applications. I'll focus on the technology that helped to build models used in ChatGPT, Google Gemini, Stable Diffusion, and others. This is an overview about how the transformer architecture is used for vision applications starting from basics to current state-of-the-art.

Each topic below is broken down into short articles that require about 15 minutes to read.

## Short articles on transformers

[Transformer introduced for NLP (2017)](https://medium.com/@erikntaylor/transformer-introduced-for-nlp-80c02858064d)

Vision transformer (2020)

Vision-language transformer

Multimodal and foundation models

## Mini-projects using generative AI

[Review of AI scientist](https://medium.com/@erikntaylor/review-of-ai-scientist-and-related-2024-papers-by-a-human-scientist-with-help-from-gpt-4o-b53c101943ac)

Topics: research paper summary, idea generation, the AI Scientist.

[Visualizing the AI Scientist](https://medium.com/@erikntaylor/visualizing-the-ai-scientist-2aa820ffe1f6)

Topics: generative AI, text-to-image, image-to-text.

If this list grows substantially, I'll move this into a new repository on generative AI.

